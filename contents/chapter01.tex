% !TeX root = ../main.tex
\chapter{Introduction}

Over the last few years, The unprecedented demand for computing power because of a large number of popular or emerging applications (e.g., neural networks and Bioinformatics) makes CGRA become a promising platform. A CGRA (Coarse-Grained Reconﬁgurable Architectures or Coarse Grain Reconfigurable Array) is typically a 2D architecture. It consists of an array of a large number of processing elements interconnected with a mesh or mesh+ network. 

Typically, CGRA contain 
\begin{enumerate} 
    \item Processing Elements:
    Typically, processing element consists of a functional unit(FU) and a local register buffer(LRB). There are also two multiplexers to determine where data come from. Every cycle, CGRA can issue different instructions to all PEs. It doesn't need to be the same instruction as that PE executed last cycle, and that's what the "Reconﬁgurable" come from.
    \item Context Memory Controller:
     This controller is responsible for reconﬁguration to each PE. Some CGRAs, like ADRES, Silicon Hive, and MorphoSys are fully dynamically reconﬁgurable: exactly one full reconﬁguration takes place for every execution cycle\cite{ARC}. We will focus on the compilation of this type of CGRAs. 
     \item LRB(local register buffer): Register file belongs to each PE.
     \item OMB(on-chip memory buffer): An memory buffer which is shared by all PEs.
     \item Network: There is an interconnected network between neighbor PEs, so each PE can communicate with each other.
\end{enumerate}

Most CGRA systems (e.g., ADRES\cite{ADRES}, TRIPS\cite{TRIPS}, DySER)\cite[]{DySER} limit the size of the array to less than 64 PEs. There are some likely reason about this situation. First, the early pioneering CGRAs are typically focus on image-, audio-, or telecommunication applications\cite{SURVEY}. SRP is Samsung’s proprietary DSP processor since 2005\cite{SRP} and SRP is a variation of ADRES. Second, compilation is a major problem of this architecture even when the size of CGRA is not that big. And if compilation time is matter, it will be way more hard to get an acceptable compilation when the size of CGRA gets bigger. We will discuss this topic further in the following chapter.

In CGRA, each PE can consume its necessary data directly from its or its neighbor's PE produced last cycle or from CGRA's routing resources. There are some common routing resources provided by CGRA. PE, LRB and OMB. Through all these routing resources, data can show up at the right time and right place. Each routing resource has its own advantage and disadvantage. So how to utilize these resources efficiently is the major issue of CGRA compiling. 
\begin{enumerate} 
    \item PE: If the compiler choose a PE to be the routing source, it can't be a computing source at the same cycle. SO in CCF(CGRA Compilation Framework)\cite{CCF}, routing instruction to PE is simply implemented as an add zero instruction. And also CCF is the experimental environment of this article.
    \item LRB: LRB is only touchable by its master PE, so no other PE can get data directly. If other PE wants data from LRB not belong to itself, it needs that LRB's master PE to be a routing PE and transfer data to its consumer. It takes one additional cycle. Because of this constraint, compiler should endeavour to map data's producer node and consumer node to the same PE if the data are routed by the LRB. In addition to this constraint, LRB also has some constraints and we will discuss them further when we talk about the detail of mapping a program to CGRA.
    \item OMB: It's a global buffer accessible to all PEs but also the last pick of routing. It takes additional load/store operations when compiler using it to route data. Also, the energy consumption of the memory isn't ideal when compare to other routing source.
\end{enumerate}

補充架構示意圖


